<!DOCTYPE html>
<html lang="ko-KR">
  <head>
    <meta content="IE=11.0000" http-equiv="X-UA-Compatible">
    <meta charset="utf-8">
    <title>Applications of Natural Language Processing:
      Transformers-based Methodologies</title>
    <meta name="author" content="Hyopil Shin">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="index_files/bootstrap.css" rel="stylesheet">
    <link href="index_files/bootstrap-responsive.css" rel="stylesheet">
    <link href="index_files/mass60.css" rel="stylesheet">
    <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  </head>
  <body style="padding-top: 30px;" vlink="#551A8B" text="#000000"
    link="#0000EE" bgcolor="#cc0000" alink="#EE0000">
    <font face="Trebuchet MS"> </font>
    <p><!--
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="#">Project name</a>
          <div class="nav-collapse">
            <ul class="nav">
              <li class="active"><a href="#">Home</a></li>
              <li><a href="#about">About</a></li>
              <li><a href="#contact">Contact</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    --> </p>
    <font face="Trebuchet MS"> </font>
    <div class="container">
      <!-- Main hero unit for a primary marketing message or call to action -->
      <div class="hero-unit">
        <h2><font face="Trebuchet MS" size="+3">M3239.001100: 자연어처리의 응용:
            트랜스포머기반 방법론들<br>
            (Applications of Natural Language Processing:
            Transformers-based Methodologies)<br>
          </font></h2>
        <h2><font face="Trebuchet MS" size="+3">108.535A: 컴퓨터언어학연구 II:
            트랜스포머기반 방법론들</font></h2>
        <h2><font face="Trebuchet MS" size="+3">(Studies on
            Computational Linguistics II: Transformers-based
            Methodologies)<br>
          </font></h2>
        <p><font face="Trebuchet MS"><br>
          </font> </p>
        <p><font face="Trebuchet MS" size="+1">Hyopil Shin (Graduate
            School of Data Science and Dept. of Linguistics, Seoul
            National University)</font></p>
        <font face="Trebuchet MS" size="+1"> </font>
        <p><font face="Trebuchet MS" size="+1"><a
              href="mailto:hpshin@snu.ac.kr">hpshin@snu.ac.kr</a><br>
          </font><font face="Trebuchet MS" size="+1"><a
              href="http://knlp.snu.ac.kr">
              <meta charset="utf-8">
            </a></font><font face="Trebuchet MS" size="+1"><a
              href="http://knlp.snu.ac.kr">
              <meta charset="utf-8">
            </a><a
              href="https://sites.google.com/snu.ac.kr/gsds-nlp/home">https://sites.google.com/snu.ac.kr/gsds-nlp/home</a>
          </font><font face="Trebuchet MS" size="+1"><br>
            <a href="http://knlp.snu.ac.kr/">http://knlp.snu.ac.kr/</a></font></p>
        <p><font face="Trebuchet MS" size="+1">Tue/Thur&nbsp; 3:30 to
            4:45 in building 942 room 302<br>
          </font></p>
        <font face="Trebuchet MS" size="+1"> </font>
        <p><font face="Trebuchet MS" size="3"><font size="+1">T.A:
              이상아(visualjan@snu.ac.kr)<br>
            </font></font></p>
        <font face="Trebuchet MS">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;










          <img src="transformer1.jpeg" alt="transformer1" width="268"
            height="150"></font><font face="Trebuchet MS">&nbsp; <img
            src="transformer3.png" alt="Transformer Architectures"
            width="266" height="153">&nbsp;<img
            src="huggingface_logo.svg" alt="Huggingface logo"
            width="161" height="150">&nbsp; </font><font
          face="Trebuchet MS"><img src="transformer.png"
            alt="transformer" width="282" height="149"></font>
        <p><font face="Trebuchet MS">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;










            (</font><font face="Trebuchet MS">
            <meta charset="utf-8">
            <span style="color: rgb(117, 117, 117); font-family: sohne,
              &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;
              font-size: 14px; font-style: normal;
              font-variant-ligatures: normal; font-variant-caps: normal;
              font-weight: 400; letter-spacing: normal; orphans: 2;
              text-align: center; text-indent: 0px; text-transform:
              none; white-space: normal; widows: 2; word-spacing: 0px;
              -webkit-text-stroke-width: 0px; background-color: rgb(255,
              255, 255); text-decoration-thickness: initial;
              text-decoration-style: initial; text-decoration-color:
              initial; display: inline !important; float: none;">Photo
              by<span>&nbsp;</span></span><a
href="https://unsplash.com/@tetrakiss?utm_source=medium&amp;utm_medium=referral"
              class="cv km" rel="noopener nofollow" style="box-sizing:
              inherit; color: inherit; text-decoration: underline;
              -webkit-tap-highlight-color: transparent; font-family:
              sohne, &quot;Helvetica Neue&quot;, Helvetica, Arial,
              sans-serif; font-size: 14px; font-style: normal;
              font-variant-ligatures: normal; font-variant-caps: normal;
              font-weight: 400; letter-spacing: normal; orphans: 2;
              text-align: center; text-indent: 0px; text-transform:
              none; white-space: normal; widows: 2; word-spacing: 0px;
              -webkit-text-stroke-width: 0px; background-color: rgb(255,
              255, 255);">Arseny Togulev</a><span style="color: rgb(117,
              117, 117); font-family: sohne, &quot;Helvetica Neue&quot;,
              Helvetica, Arial, sans-serif; font-size: 14px; font-style:
              normal; font-variant-ligatures: normal; font-variant-caps:
              normal; font-weight: 400; letter-spacing: normal; orphans:
              2; text-align: center; text-indent: 0px; text-transform:
              none; white-space: normal; widows: 2; word-spacing: 0px;
              -webkit-text-stroke-width: 0px; background-color: rgb(255,
              255, 255); text-decoration-thickness: initial;
              text-decoration-style: initial; text-decoration-color:
              initial; display: inline !important; float: none;"><span>&nbsp;</span>on<span>&nbsp;</span></span><a
href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral"
              class="cv km" rel="noopener nofollow" style="box-sizing:
              inherit; color: inherit; text-decoration: underline;
              -webkit-tap-highlight-color: transparent; font-family:
              sohne, &quot;Helvetica Neue&quot;, Helvetica, Arial,
              sans-serif; font-size: 14px; font-style: normal;
              font-variant-ligatures: normal; font-variant-caps: normal;
              font-weight: 400; letter-spacing: normal; orphans: 2;
              text-align: center; text-indent: 0px; text-transform:
              none; white-space: normal; widows: 2; word-spacing: 0px;
              -webkit-text-stroke-width: 0px; background-color: rgb(255,
              255, 255);">Unsplash</a>)<font size="3"> </font></font></p>
      </div>
      <div class="row">
        <div class="span7">
          <h2><font face="Trebuchet MS">Course Description</font></h2>
          <p><font face="Trebuchet MS" size="+1">현재 자연언어처리분야에서 Game
              Changer가 된 Transformer를 중심으로 이를 활용한 여러 응용분야들을 살펴보도록 한다.
              Transformer의 이론적 고찰에서부터 시작하여 Huggingface의 Transformers에서
              제공하는 architecture들을 살펴보고 이 중 중요한 모델들에 대해서 집중적으로 학습한다. 이를
              바탕으로 Transformer를 활용한 Sentence Bert, Question Answering,
              Search, Chatbot, Multimodal, Text
              Classification/Summarization 등을 살펴보도록 한다. 수강생들은 강의에서 제공되는
              주제들을 선택하여 관련 페이퍼와 자료들을 공부하여 발표하고 최종적으로 이를 활용한 시스템의 구현이나
              학회에 발표할 수 있는 논문을 작성할 수 있도록 한다.</font><font face="Trebuchet
              MS" size="+1"> 이 강의를 수강하기 위해서는 텍스트 및 자연어 빅데이터
              분석방법론/컴퓨터언어학연구 I 등을 수강하였거나 관련 내용을 숙지하고 있어야 한다. Python,
              Pytorch 등이 기본적으로 요구된다. 이 과목은 데이터사이언스의 자연어처리의 응용 과목과 언어학과의
              컴퓨터언어학연구 II의 Cross-listing 과목이다.<br>
            </font></p>
          <h2><font face="Trebuchet MS">Updates</font></h2>
          <ul>
            <li><font face="Trebuchet MS" size="+1">강의는 기본적으로 Zoom을 이용한
                온라인 강의. Zoom강의 주소는 학기초 ETL을 통해 공지됨</font></li>
            <li><font size="+1"><font face="Trebuchet MS">강의의 실제 자료와 주피터
                  노트북은 ETL에 탑재됨</font></font><font face="Trebuchet MS"
                size="+1"><br>
              </font></li>
          </ul>
          <ul>
          </ul>
          <ul>
          </ul>
          <h2><font face="Trebuchet MS">Useful Sites</font></h2>
          <ul>
            <li><font face="Trebuchet MS" size="+1">Lectures<br>
              </font></li>
            <font face="Trebuchet MS" size="+1"> </font>
          </ul>
          <font face="Trebuchet MS" size="+1"> </font>
          <ul>
            <ul>
              <li><font face="Trebuchet MS" size="+1"><a
                    href="http://www.nltk.org/book/">Natural Language
                    Processing with Python</a></font></li>
              <li><font face="Trebuchet MS" size="+1"><a
href="https://www.deeplearningwizard.com/deep_learning/course_progression/">Practical































































                    Deep Learning with PyTorch</a><br>
                </font></li>
            </ul>
          </ul>
          <font face="Trebuchet MS" size="+1"> </font>
          <ul>
            <li><font face="Trebuchet MS" size="+1">PyTorch</font></li>
            <ul>
              <li><font face="Trebuchet MS" size="+1"><a
                    href="https://pytorch.org/">PyTorch</a></font></li>
              <li><font face="Trebuchet MS" size="+1"><a
href="https://www.deeplearningwizard.com/deep_learning/course_progression/">Practical































































                    Deep Learning With PyTorch</a></font></li>
            </ul>
          </ul>
          <font face="Trebuchet MS" size="+1"> </font>
          <ul>
            <font face="Trebuchet MS" size="+1"> </font>
            <li><font face="Trebuchet MS" size="+1">Other Resources</font></li>
            <font face="Trebuchet MS" size="+1"> </font>
            <ul>
              <font face="Trebuchet MS" size="+1"> </font>
              <li><font face="Trebuchet MS" size="+1"><a
                    href="https://jupyter.org/">Jupyter notebook</a></font></li>
              <ul>
                <li>
                  <div><font face="Trebuchet MS"><a
href="https://towardsdatascience.com/jupyter-notebook-for-beginners-a-tutorial-f55b57c23ada"><font
                          size="+1">Jupyter notebook for beginners-A
                          tutorial</font></a></font></div>
                </li>
                <li>
                  <div><font face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/bringing-the-best-out-of-jupyter-notebooks-for-data-science-f0871519ca29">Bring





























































                        the best out of Jupyter notebooks for Data
                        science-Enhance jupyter notebook’s productivity
                        with these tips &amp; tricks</a> </font></div>
                </li>
                <li>
                  <div><font face="Trebuchet MS"><a
href="https://towardsdatascience.com/jupyter-notebook-extensions-517fa69d2231"><font
                          size="+1">Jump out of the Jupyter Notebook
                          with nbconvert</font></a></font></div>
                </li>
                <li><font face="Trebuchet MS"><a
href="https://towardsdatascience.com/jupyter-notebook-extensions-517fa69d2231"><font
                        size="+1">Jupyter Notebook Extensions</font></a></font>
                </li>
              </ul>
            </ul>
          </ul>
          <font face="Trebuchet MS"><br>
          </font>
          <ul>
            <ul>
              <font face="Trebuchet MS" size="+1"> </font>
              <li><font face="Trebuchet MS" size="+1"><a
                    href="https://colab.research.google.com/notebooks/welcome.ipynb">Google































































                    Colabatory</a></font></li>
              <ul>
                <li><font face="Trebuchet MS" size="+1"><a
href="https://medium.com/dair-ai/primer-for-learning-google-colab-bb4cabca5dd6">Primer





























































                      for Learning Google CoLab</a></font></li>
                <li><font face="Trebuchet MS"><a
href="https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c"><font
                        size="+1">Getting Started with Google CoLab</font></a></font></li>
              </ul>
            </ul>
          </ul>
          <p><br>
          </p>
          <ul>
            <ul>
              <li><font face="Trebuchet MS"><font size="+1"><font
                      face="Trebuchet MS" size="+1">Interfaces for ML
                      Models</font></font></font></li>
              <ul>
                <li><font face="Trebuchet MS"><font size="+1"><font
                        face="Trebuchet MS" size="+1"><a
                          moz-do-not-send="true"
                          href="https://www.gradio.app/">gradio</a></font></font></font></li>
                <li><font face="Trebuchet MS"><font size="+1"><font
                        face="Trebuchet MS" size="+1"><a
                          moz-do-not-send="true"
                          href="https://www.streamlit.io/">Streamlit</a><br>
                      </font></font></font></li>
              </ul>
            </ul>
          </ul>
          <p><font face="Trebuchet MS" size="+1"><a
                href="https://colab.research.google.com/notebooks/welcome.ipynb"><br>
              </a></font></p>
          <ul>
            <ul>
              <ul>
              </ul>
            </ul>
          </ul>
          <ul>
            <ul>
              <ul>
              </ul>
            </ul>
          </ul>
          <ul>
          </ul>
        </div>
        <div class="span4 offset1">
          <h2><font face="Trebuchet MS">Textbook and Sites<br>
            </font> </h2>
          <br>
          <br>
          <img src="huggingface3.png" alt="Huggingface Site" width="302"
            height="263"> <font face="Trebuchet MS" size="+1"><a
              href="https://huggingface.co/transformers/index.html">Huggingface
















              Transformers</a><br>
            <br>
            <br>
            <br>
            <a href="https://huggingface.co/transformers/index.html"> </a></font></div>
      </div>
      <div class="row" id="syllabus">
        <div class="span12">
          <h2><font face="Trebuchet MS">Syllabus</font></h2>
          <table id="tblMain" class="table table-striped" width="1006"
            height="2941" cellspacing="0" cellpadding="0" border="0">
            <tbody>
              <tr>
                <td class="s0" width="17" height="23"><font
                    face="Trebuchet MS" size="+1"><br>
                  </font> </td>
                <td class="s1" width="72" height="23" align="center"><font
                    face="Trebuchet MS" size="+1">Date</font></td>
                <td class="s1" width="350" height="23" align="center"><font
                    face="Trebuchet MS" size="+1">Topics</font></td>
                <td class="s1" width="300" height="23" align="center"><font
                    face="Trebuchet MS" size="+1">Related Materials and
                    Resources</font><font face="Trebuchet MS" size="+1"><br>
                  </font> </td>
                <td class="s1" width="380" height="23" align="center"><font
                    face="Trebuchet MS" size="+1">Repositories<br>
                  </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="160"><font
                    face="Trebuchet MS" size="+1">1</font></td>
                <td class="s3" width="72" height="160"><font
                    face="Trebuchet MS" size="+1">3/2 &amp; 3/4<br>
                  </font></td>
                <td class="s4" width="390" height="160"><font
                    face="Trebuchet MS" size="+1"><b>Introduction to
                      Class</b><br>
                  </font>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"> <a
href="https://towardsdatascience.com/natural-language-processing-the-age-of-transformers-a36c0265937d">Natural








                          Language Processing: the Age of Transformers</a></font></li>
                    <li><font face="Trebuchet MS" size="+1"><a
                          moz-do-not-send="true"
href="https://towardsdatascience.com/nlp-supervised-learning-survey-f5193c4120dc">NLP



                          for Supervised Learning- A Brief Survey</a><br>
                      </font></li>
                  </ul>
                  <font face="Trebuchet MS" size="+1"> <b>Encoder-Decoder



                      Review </b><br>
                  </font><br>
                  <meta charset="utf-8">
                  <b style="color: rgb(51, 51, 51); font-family:
                    &quot;Trebuchet MS&quot;; font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; letter-spacing: normal;
                    orphans: 2; text-align: left; text-indent: 0px;
                    text-transform: none; white-space: normal; widows:
                    2; word-spacing: 0px; -webkit-text-stroke-width:
                    0px; background-color: rgb(249, 249, 249);
                    text-decoration-thickness: initial;
                    text-decoration-style: initial;
                    text-decoration-color: initial;">Attention Model</b><br
                    style="color: rgb(51, 51, 51); font-family:
                    &quot;Trebuchet MS&quot;; font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;">
                  <ul>
                    <li> <a href="https://arxiv.org/pdf/1409.0473.pdf"
                        style="color: rgb(0, 136, 204); text-decoration:
                        none; font-family: &quot;Trebuchet MS&quot;;
                        font-size: large; font-style: normal;
                        font-variant-ligatures: normal;
                        font-variant-caps: normal; font-weight: 400;
                        letter-spacing: normal; orphans: 2; text-align:
                        left; text-indent: 0px; text-transform: none;
                        white-space: normal; widows: 2; word-spacing:
                        0px; -webkit-text-stroke-width: 0px;
                        background-color: rgb(249, 249, 249);"><font
                          face="Trebuchet MS"></font></a><font
                        face="Trebuchet MS"><a
href="https://medium.com/ai-in-plain-english/introduction-to-attention-mechanism-bahdanau-and-luong-attention-e2efd6ce22da"
                          style="color: rgb(0, 136, 204);
                          text-decoration: none; font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);"
                          moz-do-not-send="true"><font face="Trebuchet
                            MS"><font face="Trebuchet MS">Introduction
                              to Attention Mechanism: Bahdanau and Luong
                              Attention</font></font></a></font></li>
                  </ul>
                  <font face="Trebuchet MS" size="+1">
                    <meta charset="utf-8">
                  </font></td>
                <td class="s4" width="300" height="160"><font
                    face="Trebuchet MS"><a
href="https://github.com/patrickvonplaten/notebooks/blob/master/Encoder_Decoder_Model.ipynb"
                      style="color: rgb(0, 136, 204); text-decoration:
                      none; font-family: &quot;Trebuchet MS&quot;;
                      font-size: large; font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; font-weight: 400; letter-spacing: normal;
                      orphans: 2; text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);"
                      moz-do-not-send="true"><font face="Trebuchet MS"><font
                          face="Trebuchet MS">Transformer-based
                          Encoder-Decoder Models</font></font></a></font><br>
                  <font face="Trebuchet MS">
                    <meta charset="utf-8">
                    <br>
                    <a
href="https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3"
                      style="color: rgb(0, 136, 204); text-decoration:
                      none; font-family: &quot;Trebuchet MS&quot;;
                      font-size: large; font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; font-weight: 400; letter-spacing: normal;
                      orphans: 2; text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);"><font
                        face="Trebuchet MS"><font face="Trebuchet MS">Attention:









                          Illustrated Attention</font></font></a><br>
                    <br>
                    <br>
                  </font></td>
                <td class="s4" width="380" height="160"><font
                    face="Trebuchet MS"><font style="color: rgb(51, 51,
                      51); font-style: normal; font-variant-ligatures:
                      normal; font-variant-caps: normal; font-weight:
                      400; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial; background-color:
                      rgb(255, 255, 255);" face="Trebuchet MS" size="+1"><b>P</b></font><font
                      style="color: rgb(51, 51, 51); font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; font-weight: 400; letter-spacing: normal;
                      orphans: 2; text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial; background-color:
                      rgb(255, 255, 255);" face="Trebuchet MS" size="+1"><font
                        face="Trebuchet MS" size="+1"><b>yTorch:</b><br>
                      </font></font><span style="color: rgb(51, 51, 51);
                      font-family: &quot;Helvetica Neue&quot;,
                      Helvetica, Arial, sans-serif; font-size: 13px;
                      font-style: normal; font-variant-ligatures:
                      normal; font-variant-caps: normal; font-weight:
                      400; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial; background-color:
                      rgb(255, 255, 255); float: none; display: inline
                      !important;"></span><span style="color: rgb(51,
                      51, 51); font-family: &quot;Helvetica Neue&quot;,
                      Helvetica, Arial, sans-serif; font-size: 13px;
                      font-style: normal; font-variant-ligatures:
                      normal; font-variant-caps: normal; font-weight:
                      400; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);
                      text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial; display: inline
                      !important; float: none;"></span></font>
                  <ul style="margin: 0px 0px 9px 25px; padding: 0px;
                    color: rgb(51, 51, 51); font-family: &quot;Helvetica
                    Neue&quot;, Helvetica, Arial, sans-serif; font-size:
                    13px; font-style: normal; font-variant-ligatures:
                    normal; font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px;
                    text-decoration-thickness: initial;
                    text-decoration-style: initial;
                    text-decoration-color: initial; background-color:
                    rgb(255, 255, 255);">
                    <li style="line-height: 18px;"><font face="Trebuchet
                        MS" size="+1"><font face="Trebuchet MS"
                          size="+1"><a
                            href="https://github.com/bentrevett/pytorch-seq2seq"
                            style="color: rgb(0, 136, 204);
                            text-decoration: none;">pytorch-seq2seq</a></font></font></li>
                    <ul style="margin: 0px 0px 0px 25px; padding: 0px;">
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Sequence to
                            Sequence Learning with Neural Networks</font></font></li>
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Learning
                            Phrase Representations using RNN
                            Encoder-Decoder for Statistical Machine
                            Translation</font></font></li>
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Neural Machine
                            Translation by Jointly Learning to Align and
                            Translate</font></font></li>
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Packed Padded
                            Sequences, Masking, Inference and BLEU</font></font></li>
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Convolutional
                            Sequence to Sequence Learning</font></font></li>
                      <li style="line-height: 18px;"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1">Attention is
                            All You Need</font></font></li>
                    </ul>
                  </ul>
                  <font face="Trebuchet MS"> </font></td>
              </tr>
              <tr>
                <td valign="top"><font face="Trebuchet MS" size="+1">2</font></td>
                <td valign="top"><font face="Trebuchet MS" size="+1">3/9
                    &amp; 3/11</font></td>
                <td valign="top"><b><font face="Trebuchet MS" size="+1">Introduction








                      to Transformer</font></b><font face="Trebuchet MS"><br>
                  </font>
                  <ul>
                    <li> <font style="color: rgb(51, 51, 51);
                        font-family: &quot;Trebuchet MS&quot;;
                        font-size: large; font-style: normal;
                        font-variant-ligatures: normal;
                        font-variant-caps: normal; font-weight: 400;
                        letter-spacing: normal; orphans: 2; text-align:
                        left; text-indent: 0px; text-transform: none;
                        white-space: normal; widows: 2; word-spacing:
                        0px; -webkit-text-stroke-width: 0px;
                        background-color: rgb(255, 255, 255);
                        text-decoration-thickness: initial;
                        text-decoration-style: initial;
                        text-decoration-color: initial;" face="Trebuchet
                        MS" size="+1">Self Attention:<span>&nbsp;</span><a
                          href="https://arxiv.org/pdf/1706.03762.pdf"
                          style="color: rgb(0, 136, 204);
                          text-decoration: none;">Attention is All you
                          need</a></font></li>
                  </ul>
                  <ul>
                    <li> <font style="color: rgb(51, 51, 51);
                        font-family: &quot;Trebuchet MS&quot;;
                        font-size: large; font-style: normal;
                        font-variant-ligatures: normal;
                        font-variant-caps: normal; font-weight: 400;
                        letter-spacing: normal; orphans: 2; text-align:
                        left; text-indent: 0px; text-transform: none;
                        white-space: normal; widows: 2; word-spacing:
                        0px; -webkit-text-stroke-width: 0px;
                        background-color: rgb(255, 255, 255);
                        text-decoration-thickness: initial;
                        text-decoration-style: initial;
                        text-decoration-color: initial;" face="Trebuchet
                        MS" size="+1"><font face="Trebuchet MS"
                          size="+1"><a
                            href="https://jalammar.github.io/illustrated-transformer/"
                            style="color: rgb(0, 136, 204);
                            text-decoration: none;">The Illustrated
                            Transformer</a></font></font></li>
                  </ul>
                  <font style="color: rgb(51, 51, 51); font-family:
                    &quot;Trebuchet MS&quot;; font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(255, 255, 255); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><font face="Trebuchet MS" size="+1"> </font></font>
                  <meta charset="utf-8">
                  <font style="color: rgb(51, 51, 51); font-style:
                    normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px;
                    text-decoration-thickness: initial;
                    text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><font face="Trebuchet MS" size="+1"><font
                        face="Trebuchet MS" size="+1"><font
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS" size="+1"><font
                              face="Trebuchet MS" size="+1"><font
                                size="+1"><font face="Trebuchet MS"><b><br>
                                    BERT</b></font></font><b><span>&nbsp;</span></b><b>(Bidirectional








                                Encoder Representations from
                                Transformers)</b></font><font
                              face="Trebuchet MS" size="+1"><br>
                            </font></font></font></font></font></font><span
                    style="color: rgb(51, 51, 51); font-family:
                    &quot;Helvetica Neue&quot;, Helvetica, Arial,
                    sans-serif; font-size: 13px; font-style: normal;
                    font-variant-ligatures: normal; font-variant-caps:
                    normal; font-weight: 400; letter-spacing: normal;
                    orphans: 2; text-align: left; text-indent: 0px;
                    text-transform: none; white-space: normal; widows:
                    2; word-spacing: 0px; -webkit-text-stroke-width:
                    0px; background-color: rgb(249, 249, 249);
                    text-decoration-thickness: initial;
                    text-decoration-style: initial;
                    text-decoration-color: initial; display: inline
                    !important; float: none;"></span>
                  <ul style="margin: 0px 0px 9px 25px; padding: 0px;
                    color: rgb(51, 51, 51); font-family: &quot;Helvetica
                    Neue&quot;, Helvetica, Arial, sans-serif; font-size:
                    13px; font-style: normal; font-variant-ligatures:
                    normal; font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px;
                    text-decoration-thickness: initial;
                    text-decoration-style: initial;
                    text-decoration-color: initial;">
                    <li style="line-height: 18px;"><font size="+1"><a
                          href="http://jalammar.github.io/illustrated-bert/"
                          style="color: rgb(0, 136, 204);
                          text-decoration: none;"><font face="Trebuchet
                            MS">The Illustrated BERT, ELMo, and co. (How
                            NLP cracked Transfer Learning)</font></a></font></li>
                  </ul>
                  <br>
                  <ul>
                    <li><font style="color: rgb(51, 51, 51);
                        font-family: &quot;Trebuchet MS&quot;;
                        font-size: large; font-style: normal;
                        font-variant-ligatures: normal;
                        font-variant-caps: normal; font-weight: 400;
                        letter-spacing: normal; orphans: 2; text-align:
                        left; text-indent: 0px; text-transform: none;
                        white-space: normal; widows: 2; word-spacing:
                        0px; -webkit-text-stroke-width: 0px;
                        background-color: rgb(255, 255, 255);
                        text-decoration-thickness: initial;
                        text-decoration-style: initial;
                        text-decoration-color: initial;" face="Trebuchet
                        MS" size="+1"><a
href="https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598"
                          style="color: rgb(0, 136, 204);
                          text-decoration: none;" moz-do-not-send="true">FROM



                          Pre-trained Word Embeddings TO Pre-trained
                          Language Models - Focused on BERT</a></font></li>
                  </ul>
                </td>
                <td valign="top">
                  <meta charset="utf-8">
                  <font style="color: rgb(51, 51, 51); font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><b><font face="Trebuchet MS" color="red"
                        size="3"><font style="color: rgb(51, 51, 51);
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS">BERT Fine Tuning<br>
                          </font></font></font></b></font><font
                    style="color: rgb(51, 51, 51); font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><b><font face="Trebuchet MS" color="red"
                        size="3"><font style="color: rgb(51, 51, 51);
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><a
                                href="https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
                                style="color: rgb(0, 136, 204);
                                text-decoration: none;">BERT<font
                                  color="red"><b><span>&nbsp;</span></b></font>Fine-Tuning








                                Tutorial with PyTorch</a><br>
                              <br>
                              <a
                                href="https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
                                style="color: rgb(0, 136, 204);
                                text-decoration: none;">BERT Word
                                Embeddings</a><br>
                            </font></font></font></font></b></font><br>
                  <font style="color: rgb(51, 51, 51); font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><b><font face="Trebuchet MS" color="red"
                        size="3"><font style="color: rgb(51, 51, 51);
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><font style="color: rgb(51,
                                51, 51); font-size: large; font-style:
                                normal; font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(249, 249, 249);
                                text-decoration-thickness: initial;
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><b><font
                                    face="Trebuchet MS" color="red"
                                    size="3"><font style="color: rgb(51,
                                      51, 51); font-style: normal;
                                      font-variant-ligatures: normal;
                                      font-variant-caps: normal;
                                      font-weight: 400; letter-spacing:
                                      normal; orphans: 2; text-align:
                                      left; text-indent: 0px;
                                      text-transform: none; white-space:
                                      normal; widows: 2; word-spacing:
                                      0px; -webkit-text-stroke-width:
                                      0px; background-color: rgb(255,
                                      255, 255); text-decoration-style:
                                      initial; text-decoration-color:
                                      initial;" face="Trebuchet MS"
                                      size="+1"><font face="Trebuchet
                                        MS"><font face="Trebuchet MS"
                                          size="+1"><a
href="https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452"
                                            style="color: rgb(0, 136,
                                            204); text-decoration:
                                            none;"
                                            moz-do-not-send="true">Transformers



                                            Explained Visually(Part 1):
                                            Overview of Functionality</a><br>
                                          <br>
                                          <a
href="https://towardsdatascience.com/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34"
                                            style="color: rgb(0, 136,
                                            204); text-decoration:
                                            none;"
                                            moz-do-not-send="true">Transformers



                                            Explained Visually(Part 2):
                                            How it works, step-by-step</a><br>
                                          <br>
                                          <a
href="https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853"
                                            style="color: rgb(0, 136,
                                            204); text-decoration:
                                            none;"
                                            moz-do-not-send="true">Transformers



                                            Explained Visually(Part3):
                                            Multi-head Attention, deep
                                            dive</a><br>
                                          <br>
                                        </font></font></font></font></b></font></font></font></font></font></b></font><font
                    style="color: rgb(51, 51, 51); font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><b><font face="Trebuchet MS" color="red"
                        size="3"><font style="color: rgb(51, 51, 51);
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><font style="color: rgb(51,
                                51, 51); font-size: large; font-style:
                                normal; font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(249, 249, 249);
                                text-decoration-thickness: initial;
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><b><font
                                    face="Trebuchet MS" color="red"
                                    size="3"><font style="color: rgb(51,
                                      51, 51); font-style: normal;
                                      font-variant-ligatures: normal;
                                      font-variant-caps: normal;
                                      font-weight: 400; letter-spacing:
                                      normal; orphans: 2; text-align:
                                      left; text-indent: 0px;
                                      text-transform: none; white-space:
                                      normal; widows: 2; word-spacing:
                                      0px; -webkit-text-stroke-width:
                                      0px; background-color: rgb(255,
                                      255, 255); text-decoration-style:
                                      initial; text-decoration-color:
                                      initial;" face="Trebuchet MS"
                                      size="+1"><font face="Trebuchet
                                        MS"><font face="Trebuchet MS"
                                          size="+1"><a
href="https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3"
                                            style="color: rgb(0, 136,
                                            204); text-decoration:
                                            none;"
                                            moz-do-not-send="true">Master



                                            Positional Encoding: Part I</a><br>
                                          <br>
                                          <a moz-do-not-send="true"
                                            href="https://arxiv.org/abs/2009.14794">Rethinking</a><a
                                            moz-do-not-send="true"
                                            href="https://arxiv.org/abs/2009.14794">
                                            Attention with Performers</a><br>
                                          <br>
                                          <a moz-do-not-send="true"
href="https://towardsdatascience.com/from-transformers-to-performers-approximating-attention-69c88af0b11f">From



                                            Transformers to Performers:
                                            Approximating Attention</a><br>
                                          <br>
                                          <a moz-do-not-send="true"
                                            href="https://arxiv.org/pdf/2101.03961.pdf">SWITCH



                                            TRANSFORMERS: Scaling to
                                            Trillion Parameter Models
                                            with Simple and Efficient
                                            Sparsity</a><br>
                                          <br>
                                          <a moz-do-not-send="true"
href="https://towardsdatascience.com/google-switch-transformers-scaling-to-trillion-parameter-models-with-constant-computational-costs-806fd145923d">Google



                                            Switch Transformers: Scaling
                                            to Trillion Parameter Models
                                            with Constant Computational
                                            Costs</a><br>
                                        </font></font></font></font></b></font></font></font></font></font></b></font><font
                    style="color: rgb(51, 51, 51); font-size: large;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px; background-color:
                    rgb(249, 249, 249); text-decoration-thickness:
                    initial; text-decoration-style: initial;
                    text-decoration-color: initial;" face="Trebuchet MS"
                    size="+1"><b><font face="Trebuchet MS" color="red"
                        size="3"><font style="color: rgb(51, 51, 51);
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          font-weight: 400; letter-spacing: normal;
                          orphans: 2; text-align: left; text-indent:
                          0px; text-transform: none; white-space:
                          normal; widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"> </font></font></font></font></b></font></td>
                <td valign="top"><font face="Trebuchet MS" size="+1">PyTorch:<br>
                    <a
href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#embeddings-and-softmax">The








                      Annotated Transformer</a><br>
                  </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="150"><font
                    face="Trebuchet MS" size="+1">3</font></td>
                <td class="s3" width="72" height="150"><font
                    face="Trebuchet MS" size="+1">3/16 &amp; 3/18</font></td>
                <td class="s4" width="390" height="150"><font
                    face="Trebuchet MS" size="+1"><b>Introduction to
                      Huggingface Transformers</b></font><br>
                  <ul>
                    <li> <font face="Trebuchet MS" size="+1">
                        <meta charset="utf-8">
                        <b style="color: rgb(51, 51, 51); font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);
                          text-decoration-thickness: initial;
                          text-decoration-style: initial;
                          text-decoration-color: initial;"><font
                            face="Trebuchet MS" color="red" size="3"><font
                              style="color: rgb(51, 51, 51); font-style:
                              normal; font-variant-ligatures: normal;
                              font-variant-caps: normal; font-weight:
                              400; letter-spacing: normal; orphans: 2;
                              text-align: left; text-indent: 0px;
                              text-transform: none; white-space: normal;
                              widows: 2; word-spacing: 0px;
                              -webkit-text-stroke-width: 0px;
                              background-color: rgb(255, 255, 255);
                              text-decoration-style: initial;
                              text-decoration-color: initial;"
                              face="Trebuchet MS" size="+1"><font
                                face="Trebuchet MS"><font
                                  face="Trebuchet MS" size="+1"><font
                                    face="Trebuchet MS" size="+1"><a
                                      href="https://huggingface.co/transformers/quicktour.html"
                                      style="color: rgb(0, 136, 204);
                                      text-decoration: none;">Quick Tour</a></font></font></font></font></font></b></font></li>
                  </ul>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"><b
                          style="color: rgb(51, 51, 51); font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);
                          text-decoration-thickness: initial;
                          text-decoration-style: initial;
                          text-decoration-color: initial;"><font
                            face="Trebuchet MS" color="red" size="3"><font
                              style="color: rgb(51, 51, 51); font-style:
                              normal; font-variant-ligatures: normal;
                              font-variant-caps: normal; font-weight:
                              400; letter-spacing: normal; orphans: 2;
                              text-align: left; text-indent: 0px;
                              text-transform: none; white-space: normal;
                              widows: 2; word-spacing: 0px;
                              -webkit-text-stroke-width: 0px;
                              background-color: rgb(255, 255, 255);
                              text-decoration-style: initial;
                              text-decoration-color: initial;"
                              face="Trebuchet MS" size="+1"><font
                                face="Trebuchet MS"><font
                                  face="Trebuchet MS" size="+1"><font
                                    face="Trebuchet MS" size="+1"> <a
                                      href="https://huggingface.co/transformers/task_summary.html"
                                      style="color: rgb(0, 136, 204);
                                      text-decoration: none;">Summary of
                                      Tasks</a><span>&nbsp;</span>:
                                    Sequence Classification, Extractive
                                    Question Answering, Language
                                    Modeling, Text Generation, Named
                                    Entity Recognition, Summarization,
                                    and Translation</font></font></font></font></font></b></font></li>
                  </ul>
                  <font face="Trebuchet MS" size="+1"><b style="color:
                      rgb(51, 51, 51); font-family: &quot;Trebuchet
                      MS&quot;; font-size: large; font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);
                      text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial;"><font
                        face="Trebuchet MS" color="red" size="3"><font
                          style="color: rgb(51, 51, 51); font-style:
                          normal; font-variant-ligatures: normal;
                          font-variant-caps: normal; font-weight: 400;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><font face="Trebuchet MS"
                                size="+1"> </font></font></font></font></font></b></font><br>
                  <font face="Trebuchet MS" size="+1"><b style="color:
                      rgb(51, 51, 51); font-family: &quot;Trebuchet
                      MS&quot;; font-size: large; font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);
                      text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial;"><font
                        face="Trebuchet MS" color="red" size="3"><font
                          style="color: rgb(51, 51, 51); font-style:
                          normal; font-variant-ligatures: normal;
                          font-variant-caps: normal; font-weight: 400;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><font face="Trebuchet MS"
                                size="+1"><b><font face="Trebuchet MS"
                                    size="+1">Some</font></b><b> Models
                                  for Long Sequences</b><br>
                              </font></font></font></font></font></b></font><br>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"><b
                          style="color: rgb(51, 51, 51); font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);
                          text-decoration-thickness: initial;
                          text-decoration-style: initial;
                          text-decoration-color: initial;"><font
                            face="Trebuchet MS" color="red" size="3"><font
                              style="color: rgb(51, 51, 51); font-style:
                              normal; font-variant-ligatures: normal;
                              font-variant-caps: normal; font-weight:
                              400; letter-spacing: normal; orphans: 2;
                              text-align: left; text-indent: 0px;
                              text-transform: none; white-space: normal;
                              widows: 2; word-spacing: 0px;
                              -webkit-text-stroke-width: 0px;
                              background-color: rgb(255, 255, 255);
                              text-decoration-style: initial;
                              text-decoration-color: initial;"
                              face="Trebuchet MS" size="+1"><font
                                face="Trebuchet MS"><font
                                  face="Trebuchet MS" size="+1"><font
                                    face="Trebuchet MS" size="+1"><a
                                      href="https://arxiv.org/pdf/2007.14062.pdf"
                                      style="color: rgb(0, 136, 204);
                                      text-decoration: none;">Big Bird:
                                      Transformers for Longer Sequences</a></font></font></font></font></font></b></font></li>
                    <ul>
                      <li><font face="Trebuchet MS" size="+1"><b
                            style="color: rgb(51, 51, 51); font-family:
                            &quot;Trebuchet MS&quot;; font-size: large;
                            font-style: normal; font-variant-ligatures:
                            normal; font-variant-caps: normal;
                            letter-spacing: normal; orphans: 2;
                            text-align: left; text-indent: 0px;
                            text-transform: none; white-space: normal;
                            widows: 2; word-spacing: 0px;
                            -webkit-text-stroke-width: 0px;
                            background-color: rgb(249, 249, 249);
                            text-decoration-thickness: initial;
                            text-decoration-style: initial;
                            text-decoration-color: initial;"><font
                              face="Trebuchet MS" color="red" size="3"><font
                                style="color: rgb(51, 51, 51);
                                font-style: normal;
                                font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(255, 255, 255);
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><font
                                  face="Trebuchet MS"><font
                                    face="Trebuchet MS" size="+1"><font
                                      face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/understanding-bigbird-is-it-another-big-milestone-in-nlp-e7546b2c9643">Understanding







                                        Google's BigBird - Is It Another
                                        Big Milestone In NLP?</a></font></font></font></font></font></b></font></li>
                    </ul>
                    <li><font face="Trebuchet MS" size="+1"><b
                          style="color: rgb(51, 51, 51); font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);
                          text-decoration-thickness: initial;
                          text-decoration-style: initial;
                          text-decoration-color: initial;"><font
                            face="Trebuchet MS" color="red" size="3"><font
                              style="color: rgb(51, 51, 51); font-style:
                              normal; font-variant-ligatures: normal;
                              font-variant-caps: normal; font-weight:
                              400; letter-spacing: normal; orphans: 2;
                              text-align: left; text-indent: 0px;
                              text-transform: none; white-space: normal;
                              widows: 2; word-spacing: 0px;
                              -webkit-text-stroke-width: 0px;
                              background-color: rgb(255, 255, 255);
                              text-decoration-style: initial;
                              text-decoration-color: initial;"
                              face="Trebuchet MS" size="+1"><font
                                face="Trebuchet MS"><font
                                  face="Trebuchet MS" size="+1"><font
                                    face="Trebuchet MS" size="+1"><a
                                      href="https://arxiv.org/pdf/2001.04451.pdf">REFORMER:







                                      The Efficient Transformer</a></font></font></font></font></font></b></font></li>
                    <ul>
                      <li><font face="Trebuchet MS" size="+1"><b
                            style="color: rgb(51, 51, 51); font-family:
                            &quot;Trebuchet MS&quot;; font-size: large;
                            font-style: normal; font-variant-ligatures:
                            normal; font-variant-caps: normal;
                            letter-spacing: normal; orphans: 2;
                            text-align: left; text-indent: 0px;
                            text-transform: none; white-space: normal;
                            widows: 2; word-spacing: 0px;
                            -webkit-text-stroke-width: 0px;
                            background-color: rgb(249, 249, 249);
                            text-decoration-thickness: initial;
                            text-decoration-style: initial;
                            text-decoration-color: initial;"><font
                              face="Trebuchet MS" color="red" size="3"><font
                                style="color: rgb(51, 51, 51);
                                font-style: normal;
                                font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(255, 255, 255);
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><font
                                  face="Trebuchet MS"><font
                                    face="Trebuchet MS" size="+1"><font
                                      face="Trebuchet MS" size="+1"><a
                                        href="https://github.com/patrickvonplaten/notebooks.git">Github







                                        of patrickvonplaten for Reformer</a></font></font></font></font></font></b></font></li>
                      <li><font face="Trebuchet MS" size="+1"><b
                            style="color: rgb(51, 51, 51); font-family:
                            &quot;Trebuchet MS&quot;; font-size: large;
                            font-style: normal; font-variant-ligatures:
                            normal; font-variant-caps: normal;
                            letter-spacing: normal; orphans: 2;
                            text-align: left; text-indent: 0px;
                            text-transform: none; white-space: normal;
                            widows: 2; word-spacing: 0px;
                            -webkit-text-stroke-width: 0px;
                            background-color: rgb(249, 249, 249);
                            text-decoration-thickness: initial;
                            text-decoration-style: initial;
                            text-decoration-color: initial;"><font
                              face="Trebuchet MS" color="red" size="3"><font
                                style="color: rgb(51, 51, 51);
                                font-style: normal;
                                font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(255, 255, 255);
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><font
                                  face="Trebuchet MS"><font
                                    face="Trebuchet MS" size="+1"><font
                                      face="Trebuchet MS" size="+1"><a
                                        moz-do-not-send="true"
                                        href="https://www.pragmatic.ml/reformer-deep-dive/">A
                                        Deep Dive into the Reformer</a></font></font></font></font></font></b></font></li>
                      <li><font face="Trebuchet MS" size="+1"><b
                            style="color: rgb(51, 51, 51); font-family:
                            &quot;Trebuchet MS&quot;; font-size: large;
                            font-style: normal; font-variant-ligatures:
                            normal; font-variant-caps: normal;
                            letter-spacing: normal; orphans: 2;
                            text-align: left; text-indent: 0px;
                            text-transform: none; white-space: normal;
                            widows: 2; word-spacing: 0px;
                            -webkit-text-stroke-width: 0px;
                            background-color: rgb(249, 249, 249);
                            text-decoration-thickness: initial;
                            text-decoration-style: initial;
                            text-decoration-color: initial;"><font
                              face="Trebuchet MS" color="red" size="3"><font
                                style="color: rgb(51, 51, 51);
                                font-style: normal;
                                font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(255, 255, 255);
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><font
                                  face="Trebuchet MS"><font
                                    face="Trebuchet MS" size="+1"><font
                                      face="Trebuchet MS" size="+1"><a
                                        moz-do-not-send="true"
href="https://towardsdatascience.com/illustrating-the-reformer-393575ac6ba0">Illustrating


                                        the Reformer</a><br>
                                    </font></font></font></font></font></b></font></li>
                    </ul>
                    <li><font face="Trebuchet MS" size="+1"><b
                          style="color: rgb(51, 51, 51); font-family:
                          &quot;Trebuchet MS&quot;; font-size: large;
                          font-style: normal; font-variant-ligatures:
                          normal; font-variant-caps: normal;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(249, 249, 249);
                          text-decoration-thickness: initial;
                          text-decoration-style: initial;
                          text-decoration-color: initial;"><font
                            face="Trebuchet MS" color="red" size="3"><font
                              style="color: rgb(51, 51, 51); font-style:
                              normal; font-variant-ligatures: normal;
                              font-variant-caps: normal; font-weight:
                              400; letter-spacing: normal; orphans: 2;
                              text-align: left; text-indent: 0px;
                              text-transform: none; white-space: normal;
                              widows: 2; word-spacing: 0px;
                              -webkit-text-stroke-width: 0px;
                              background-color: rgb(255, 255, 255);
                              text-decoration-style: initial;
                              text-decoration-color: initial;"
                              face="Trebuchet MS" size="+1"><font
                                face="Trebuchet MS"><font
                                  face="Trebuchet MS" size="+1"><font
                                    face="Trebuchet MS" size="+1"><a
                                      moz-do-not-send="true"
                                      href="https://arxiv.org/abs/2004.05150">Longformer:



                                      The Long-Document Transformer</a></font></font></font></font></font></b></font></li>
                    <ul>
                      <li><font face="Trebuchet MS" size="+1"><b
                            style="color: rgb(51, 51, 51); font-family:
                            &quot;Trebuchet MS&quot;; font-size: large;
                            font-style: normal; font-variant-ligatures:
                            normal; font-variant-caps: normal;
                            letter-spacing: normal; orphans: 2;
                            text-align: left; text-indent: 0px;
                            text-transform: none; white-space: normal;
                            widows: 2; word-spacing: 0px;
                            -webkit-text-stroke-width: 0px;
                            background-color: rgb(249, 249, 249);
                            text-decoration-thickness: initial;
                            text-decoration-style: initial;
                            text-decoration-color: initial;"><font
                              face="Trebuchet MS" color="red" size="3"><font
                                style="color: rgb(51, 51, 51);
                                font-style: normal;
                                font-variant-ligatures: normal;
                                font-variant-caps: normal; font-weight:
                                400; letter-spacing: normal; orphans: 2;
                                text-align: left; text-indent: 0px;
                                text-transform: none; white-space:
                                normal; widows: 2; word-spacing: 0px;
                                -webkit-text-stroke-width: 0px;
                                background-color: rgb(255, 255, 255);
                                text-decoration-style: initial;
                                text-decoration-color: initial;"
                                face="Trebuchet MS" size="+1"><font
                                  face="Trebuchet MS"><font
                                    face="Trebuchet MS" size="+1"><font
                                      face="Trebuchet MS" size="+1"><a
                                        moz-do-not-send="true"
href="https://towardsdatascience.com/longformer-the-long-document-transformer-cdfeefe81e89">Longformer:



                                        The Long-Document Transformer</a><br>
                                    </font></font></font></font></font></b></font></li>
                    </ul>
                  </ul>
                </td>
                <td class="s4" width="300" height="150"><font
                    face="Trebuchet MS"><b style="color: rgb(51, 51,
                      51); font-family: &quot;Trebuchet MS&quot;;
                      font-size: large; font-style: normal;
                      font-variant-ligatures: normal; font-variant-caps:
                      normal; letter-spacing: normal; orphans: 2;
                      text-align: left; text-indent: 0px;
                      text-transform: none; white-space: normal; widows:
                      2; word-spacing: 0px; -webkit-text-stroke-width:
                      0px; background-color: rgb(249, 249, 249);
                      text-decoration-thickness: initial;
                      text-decoration-style: initial;
                      text-decoration-color: initial;"><font
                        face="Trebuchet MS" color="red" size="3"><font
                          style="color: rgb(51, 51, 51); font-style:
                          normal; font-variant-ligatures: normal;
                          font-variant-caps: normal; font-weight: 400;
                          letter-spacing: normal; orphans: 2;
                          text-align: left; text-indent: 0px;
                          text-transform: none; white-space: normal;
                          widows: 2; word-spacing: 0px;
                          -webkit-text-stroke-width: 0px;
                          background-color: rgb(255, 255, 255);
                          text-decoration-style: initial;
                          text-decoration-color: initial;"
                          face="Trebuchet MS" size="+1"><font
                            face="Trebuchet MS"><font face="Trebuchet
                              MS" size="+1"><font size="+1"><font
                                  face="Trebuchet MS" size="+1"><b><font
                                      face="Trebuchet MS" color="red"
                                      size="3"><font style="color:
                                        rgb(51, 51, 51); font-style:
                                        normal; font-variant-ligatures:
                                        normal; font-variant-caps:
                                        normal; font-weight: 400;
                                        letter-spacing: normal; orphans:
                                        2; text-align: left;
                                        text-indent: 0px;
                                        text-transform: none;
                                        white-space: normal; widows: 2;
                                        word-spacing: 0px;
                                        -webkit-text-stroke-width: 0px;
                                        background-color: rgb(255, 255,
                                        255); text-decoration-style:
                                        initial; text-decoration-color:
                                        initial;" face="Trebuchet MS"
                                        size="+1"><font face="Trebuchet
                                          MS"><font face="Trebuchet MS"
                                            size="+1"><a
                                              href="https://github.com/huggingface/transformers"
                                              style="color: rgb(0, 85,
                                              128); text-decoration:
                                              underline; outline: 0px;"><font
                                                size="+1"><font
                                                  face="Trebuchet MS"><b>Transformers








                                                    by Huggingface<span>&nbsp;</span></b></font></font></a><font
                                              face="Trebuchet MS"
                                              size="+1">and<span>&nbsp;</span><a
href="https://huggingface.co/transformers/index.html" style="color:
                                                rgb(0, 136, 204);
                                                text-decoration: none;">Full








                                                Documentation</a></font></font></font></font></font></b></font></font></font></font></font></font></b>
                  </font></td>
                <td class="s4" width="380" height="150"><br>
                  <ul data-pm-slice="3 3
[&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null},&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null}]"
                    data-en-clipboard="true">
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/albert.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">ALBERT</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google Research and the Toyota Technological
                          Institute at Chicago) released with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1909.11942"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">ALBERT: A
                            Lite BERT for Self-supervised Learning of
                            Language Representations</span></a><span
                          style="color:rgb(36, 41, 46);">, by Zhenzhong
                          Lan, Mingda Chen, Sebastian Goodman, Kevin
                          Gimpel, Piyush Sharma, Radu Soricut.</span></font>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/bart.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BART</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Facebook) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/pdf/1910.13461.pdf"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BART:
                              Denoising Sequence-to-Sequence
                              Pre-training for Natural Language
                              Generation, Translation, and Comprehension</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Mike
                            Lewis, Yinhan Liu, Naman Goyal, Marjan
                            Ghazvininejad, Abdelrahman Mohamed, Omer
                            Levy, Ves Stoyanov and Luke Zettlemoyer.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/barthez.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BARThez</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            École polytechnique) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2010.12321"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BARThez: a
                              Skilled Pretrained French
                              Sequence-to-Sequence Model</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Moussa Kamal Eddine, Antoine J.-P. Tixier,
                            Michalis Vazirgiannis.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/bert.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Google) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1810.04805"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BERT:
                              Pre-training of Deep Bidirectional
                              Transformers for Language Understanding</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Jacob Devlin, Ming-Wei Chang, Kenton Lee and
                            Kristina Toutanova.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/bertgeneration.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">BERT For
                              Sequence Generation</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Google) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1907.12461"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Leveraging
                              Pre-trained Checkpoints for Sequence
                              Generation Tasks</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Sascha Rothe, Shashi Narayan, Aliaksei
                            Severyn.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/blenderbot.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Blenderbot</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Facebook) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2004.13637"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Recipes for
                              building an open-domain chatbot</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Stephen Roller, Emily Dinan, Naman Goyal, Da
                            Ju, Mary Williamson, Yinhan Liu, Jing Xu,
                            Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan
                            Boureau, Jason Weston.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/camembert.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">CamemBERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Inria/Facebook/Sorbonne) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1911.03894"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">CamemBERT:
                              a Tasty French Language Model</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Louis Martin*, Benjamin Muller*, Pedro
                            Javier Ortiz Suárez*, Yoann Dupont, Laurent
                            Romary, Éric Villemonte de la Clergerie,
                            Djamé Seddah and Benoît Sagot.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/ctrl.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">CTRL</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Salesforce) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1909.05858"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">CTRL: A
                              Conditional Transformer Language Model for
                              Controllable Generation</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Nitish Shirish Keskar*, Bryan McCann*, Lav
                            R. Varshney, Caiming Xiong and Richard
                            Socher.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/deberta.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DeBERTa</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Microsoft Research) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2006.03654"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DeBERTa:
                              Decoding-enhanced BERT with Disentangled
                              Attention</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Pengcheng He, Xiaodong Liu, Jianfeng Gao,
                            Weizhu Chen.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/dialogpt.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DialoGPT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Microsoft Research) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1911.00536"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DialoGPT:
                              Large-Scale Generative Pre-training for
                              Conversational Response Generation</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Yizhe Zhang, Siqi Sun, Michel Galley,
                            Yen-Chun Chen, Chris Brockett, Xiang Gao,
                            Jianfeng Gao, Jingjing Liu, Bill Dolan.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/distilbert.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DistilBERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            HuggingFace), released together with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1910.01108"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DistilBERT,
                              a distilled version of BERT: smaller,
                              faster, cheaper and lighter</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Victor Sanh, Lysandre Debut and Thomas Wolf.
                            The same method has been applied to compress
                            GPT2 into&nbsp;</span><a
href="https://github.com/huggingface/transformers/tree/master/examples/distillation"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">DistilGPT2</span></a><span
                            style="color:rgb(36, 41, 46);">, RoBERTa
                            into&nbsp;</span><a
href="https://github.com/huggingface/transformers/tree/master/examples/distillation"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">DistilRoBERTa</span></a><span
                            style="color:rgb(36, 41, 46);">,
                            Multilingual BERT into&nbsp;</span><a
href="https://github.com/huggingface/transformers/tree/master/examples/distillation"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">DistilmBERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;and a
                            German version of DistilBERT.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/dpr.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">DPR</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Facebook) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2004.04906"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Dense
                              Passage Retrieval for Open-Domain Question
                              Answering</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Vladimir Karpukhin, Barlas Oğuz, Sewon Min,
                            Patrick Lewis, Ledell Wu, Sergey Edunov,
                            Danqi Chen, and Wen-tau Yih.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/electra.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">ELECTRA</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Google Research/Stanford University)
                            released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2003.10555"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">ELECTRA:
                              Pre-training text encoders as
                              discriminators rather than generators</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Kevin Clark, Minh-Thang Luong, Quoc V. Le,
                            Christopher D. Manning.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/flaubert.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">FlauBERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            CNRS) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1912.05372"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">FlauBERT:
                              Unsupervised Language Model Pre-training
                              for French</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Hang
                            Le, Loïc Vial, Jibril Frej, Vincent Segonne,
                            Maximin Coavoux, Benjamin Lecouteux,
                            Alexandre Allauzen, Benoît Crabbé, Laurent
                            Besacier, Didier Schwab.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/funnel.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Funnel
                              Transformer</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            CMU/Google Brain) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2006.03236"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Funnel-Transformer:











                              Filtering out Sequential Redundancy for
                              Efficient Language Processing</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Zihang Dai, Guokun Lai, Yiming Yang, Quoc V.
                            Le.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/gpt.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">GPT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            OpenAI) released with the paper&nbsp;</span><a
href="https://blog.openai.com/language-unsupervised/" rel="nofollow"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">Improving Language Understanding
                              by Generative Pre-Training</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Alec
                            Radford, Karthik Narasimhan, Tim Salimans
                            and Ilya Sutskever.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/gpt2.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">GPT-2</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            OpenAI) released with the paper&nbsp;</span><a
href="https://blog.openai.com/better-language-models/" rel="nofollow"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">Language Models are Unsupervised
                              Multitask Learners</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Alec
                            Radford*, Jeffrey Wu*, Rewon Child, David
                            Luan, Dario Amodei** and Ilya Sutskever**.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/layoutlm.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">LayoutLM</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Microsoft Research Asia) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1912.13318"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">LayoutLM:
                              Pre-training of Text and Layout for
                              Document Image Understanding</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Yiheng Xu, Minghao Li, Lei Cui, Shaohan
                            Huang, Furu Wei, Ming Zhou.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/longformer.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Longformer</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            AllenAI) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/2004.05150"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">Longformer:
                              The Long-Document Transformer</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Iz
                            Beltagy, Matthew E. Peters, Arman Cohan.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/lxmert.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">LXMERT</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            UNC Chapel Hill) released with the
                            paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1908.07490"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">LXMERT:
                              Learning Cross-Modality Encoder
                              Representations from Transformers for
                              Open-Domain Question Answering</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by Hao
                            Tan and Mohit Bansal.</span></font></div>
                    </li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/marian.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">MarianMT</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;Machine
                          translation models trained using&nbsp;</span><a
                          href="http://opus.nlpl.eu/" rel="nofollow"
                          rev="en_rl_none"><span style="color:rgb(36,
                            41, 46);">OPUS</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;data by
                          Jörg Tiedemann. The&nbsp;</span><a
                          href="https://marian-nmt.github.io/"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Marian
                            Framework</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;is being
                          developed by the Microsoft Translator Team.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/mbart.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/mbart.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">MBart</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Facebook) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2001.08210"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Multilingual
                            Denoising Pre-training for Neural Machine
                            Translation</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Yinhan
                          Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey
                          Edunov, Marjan Ghazvininejad, Mike Lewis, Luke
                          Zettlemoyer.</span></font> <font
                        face="Trebuchet MS"><span style="color:rgb(36,
                          41, 46);"></span></font><font face="Trebuchet
                        MS"><a
                          href="https://huggingface.co/transformers/model_doc/mpnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/mpnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">MPNet</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Microsoft Research) released with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2004.09297"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">MPNet: Masked
                            and Permuted Pre-training for Language
                            Understanding</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Kaitao
                          Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan
                          Liu.</span></font><font face="Trebuchet MS"><a
href="https://huggingface.co/transformers/model_doc/mt5.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/mt5.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">MT5</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google AI) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2010.11934"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">mT5: A
                            massively multilingual pre-trained
                            text-to-text transformer</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by
                          Linting Xue, Noah Constant, Adam Roberts,
                          Mihir Kale, Rami Al-Rfou, Aditya Siddhant,
                          Aditya Barua, Colin Raffel.</span></font> <font
                        face="Trebuchet MS"><span style="color:rgb(36,
                          41, 46);"></span></font><font face="Trebuchet
                        MS"><a
                          href="https://huggingface.co/transformers/model_doc/pegasus.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/pegasus.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Pegasus</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1912.08777"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">PEGASUS:
                            Pre-training with Extracted Gap-sentences
                            for Abstractive Summarization</span></a><span
                          style="color:rgb(36, 41, 46);">&gt; by
                          Jingqing Zhang, Yao Zhao, Mohammad Saleh and
                          Peter J. Liu.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/prophetnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/prophetnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">ProphetNet</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Microsoft Research) released with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2001.04063"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">ProphetNet:
                            Predicting Future N-gram for
                            Sequence-to-Sequence Pre-training</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Yu
                          Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan
                          Duan, Jiusheng Chen, Ruofei Zhang and Ming
                          Zhou.</span></font> <font face="Trebuchet MS"><span
                          style="color:rgb(36, 41, 46);"></span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/reformer.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/reformer.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Reformer</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google Research) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2001.04451"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Reformer: The
                            Efficient Transformer</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Nikita
                          Kitaev, Łukasz Kaiser, Anselm Levskaya.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/roberta.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/roberta.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">RoBERTa</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Facebook), released together with the paper
                          a&nbsp;</span><a
                          href="https://arxiv.org/abs/1907.11692"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Robustly
                            Optimized BERT Pretraining Approach</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Yinhan
                          Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar
                          Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
                          Zettlemoyer, Veselin Stoyanov. ultilingual
                          BERT into&nbsp;</span><a
href="https://github.com/huggingface/transformers/tree/master/examples/distillation"
                          rev="en_rl_none"><span style="color:rgb(36,
                            41, 46);">DistilmBERT</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;and a
                          German version of DistilBERT.</span></font>&nbsp;<font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/squeezebert.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/squeezebert.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">SqueezeBert</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;released
                          with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2006.11316"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">SqueezeBERT:
                            What can computer vision teach NLP about
                            efficient neural networks?</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by
                          Forrest N. Iandola, Albert E. Shaw, Ravi
                          Krishna, and Kurt W. Keutzer.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/t5.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/t5.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">T5</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google AI) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1910.10683"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Exploring the
                            Limits of Transfer Learning with a Unified
                            Text-to-Text Transformer</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Colin
                          Raffel and Noam Shazeer and Adam Roberts and
                          Katherine Lee and Sharan Narang and Michael
                          Matena and Yanqi Zhou and Wei Li and Peter J.
                          Liu.</span></font> <font face="Trebuchet MS"><span
                          style="color:rgb(36, 41, 46);"></span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/master/model_doc/tapas.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/master/model_doc/tapas.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">TAPAS</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google AI) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2004.02349"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">TAPAS: Weakly
                            Supervised Table Parsing via Pre-training</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by
                          Jonathan Herzig, Paweł Krzysztof Nowak, Thomas
                          Müller, Francesco Piccinno and Julian Martin
                          Eisenschlos.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/transformerxl.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/transformerxl.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Transformer-XL</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Google/CMU) released with the paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1901.02860"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Transformer-XL:











                            Attentive Language Models Beyond a
                            Fixed-Length Context</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Zihang
                          Dai*, Zhilin Yang*, Yiming Yang, Jaime
                          Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</span></font>
                      <font face="Trebuchet MS"><span
                          style="color:rgb(36, 41, 46);"></span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlm.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlm.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">XLM</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Facebook) released together with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1901.07291"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Cross-lingual
                            Language Model Pretraining</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by
                          Guillaume Lample and Alexis Conneau.</span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlmprophetnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlmprophetnet.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">XLM-ProphetNet</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Microsoft Research) released with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/2001.04063"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">ProphetNet:
                            Predicting Future N-gram for
                            Sequence-to-Sequence Pre-training</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;by Yu
                          Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan
                          Duan, Jiusheng Chen, Ruofei Zhang and Ming
                          Zhou.</span></font> <font face="Trebuchet MS"><span
                          style="color:rgb(36, 41, 46);"></span></font><font
                        face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlmroberta.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);"></span></a></font></li>
                    <li><font face="Trebuchet MS"><a
                          href="https://huggingface.co/transformers/model_doc/xlmroberta.html"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">XLM-RoBERTa</span></a><span
                          style="color:rgb(36, 41, 46);">&nbsp;(from
                          Facebook AI), released together with the
                          paper&nbsp;</span><a
                          href="https://arxiv.org/abs/1911.02116"
                          rel="nofollow" rev="en_rl_none"><span
                            style="color:rgb(36, 41, 46);">Unsupervised
                            Cross-lingual Representation Learning at
                            Scale</span></a><span style="color:rgb(36,
                          41, 46);">&nbsp;by Alexis Conneau*, Kartikay
                          Khandelwal*, Naman Goyal, Vishrav Chaudhary,
                          Guillaume Wenzek, Francisco Guzmán, Edouard
                          Grave, Myle Ott, Luke Zettlemoyer and Veselin
                          Stoyanov.</span></font></li>
                    <li>
                      <div><font face="Trebuchet MS"><a
                            href="https://huggingface.co/transformers/model_doc/xlnet.html"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">XLNet</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;(from
                            Google/CMU) released with the paper&nbsp;</span><a
                            href="https://arxiv.org/abs/1906.08237"
                            rel="nofollow" rev="en_rl_none"><span
                              style="color:rgb(36, 41, 46);">XLNet:
                              Generalized Autoregressive Pretraining for
                              Language Understanding</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;by
                            Zhilin Yang*, Zihang Dai*, Yiming Yang,
                            Jaime Carbonell, Ruslan Salakhutdinov, Quoc
                            V. Le.</span></font></div>
                    </li>
                    <li>
                      <div><font face="Trebuchet MS"><span
                            style="color:rgb(36, 41, 46);">Want to
                            contribute a new model? We have added
                            a&nbsp;detailed guide and templates&nbsp;to
                            guide you in the process of adding a new
                            model. You can find them in the&nbsp;</span><a
href="https://github.com/huggingface/transformers/blob/master/templates"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">templates</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;folder
                            of the repository. Be sure to check
                            the&nbsp;</span><a
href="https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md"
                            rev="en_rl_none"><span style="color:rgb(36,
                              41, 46);">contributing guidelines</span></a><span
                            style="color:rgb(36, 41, 46);">&nbsp;and
                            contact the maintainers or open an issue to
                            collect feedbacks before starting your PR.</span></font></div>
                    </li>
                  </ul>
                  <font face="Trebuchet MS"> </font></td>
              </tr>
              <tr>
                <td valign="top"><font face="Trebuchet MS" size="+1">4</font></td>
                <td valign="top"><font face="Trebuchet MS" size="+1">3/23








                    &amp; 3/25</font></td>
                <td valign="top"><font face="Trebuchet MS" size="+1"><b>Introduction








                      to Huggingface Transformers</b><br>
                  </font>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"><font
                          face="Trebuchet MS" size="+1"><a
                            href="https://github.com/deepset-ai/FARM">FARM:




                            Framework for Adapting Representation Models</a></font>
                      </font></li>
                  </ul>
                </td>
                <td valign="top">
                  <meta charset="utf-8">
                  <a
                    href="https://huggingface.co/transformers/notebooks.html"
                    style="color: rgb(0, 136, 204); text-decoration:
                    none; font-family: &quot;Helvetica Neue&quot;,
                    Helvetica, Arial, sans-serif; font-size: 13px;
                    font-style: normal; font-variant-ligatures: normal;
                    font-variant-caps: normal; font-weight: 400;
                    letter-spacing: normal; orphans: 2; text-align:
                    left; text-indent: 0px; text-transform: none;
                    white-space: normal; widows: 2; word-spacing: 0px;
                    -webkit-text-stroke-width: 0px;"><font size="+1"><font
                        face="Trebuchet MS" size="+1"><font
                          face="Trebuchet MS"><b><font size="+1">Huggingface








                              Transformers Notebooks</font></b></font></font></font></a><br>
                  <br>
                  <font face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/fine-tuning-bert-for-text-classification-with-farm-2880665065e2">Fine








                      Tuning BERT for Text Classification with FARM</a><br>
                  </font></td>
                <td valign="top">
                  <meta charset="utf-8">
                </td>
              </tr>
              <tr>
                <td class="s2" width="17" height="120"><font
                    face="Trebuchet MS" size="+1">5</font></td>
                <td class="s3" width="72" height="120"><font
                    face="Trebuchet MS" size="+1">3/30 </font><font
                    face="Trebuchet MS"><font size="+1"><font size="+1">&amp;







                        4/1</font></font></font></td>
                <td class="s4" width="390" height="120"><font
                    face="Trebuchet MS" size="+1"><b>Sentence Embedding
                      with Transformers </b><br>
                  </font>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"><a
                          href="https://towardsdatascience.com/sentence-embedding-3053db22ea77">Sentence








                          Embedding: Literature Review</a></font></li>
                  </ul>
                  <font face="Trebuchet MS" size="+1"> </font>
                  <ul>
                    <li><font face="Trebuchet MS" size="+1"><a
href="https://medium.com/genei-technology/richer-sentence-embeddings-using-sentence-bert-part-i-ce1d9e0b1343">Richer








                          Sentence Embeddings Using Sentence-BERT-Part I</a></font></li>
                  </ul>
                  <font face="Trebuchet MS" size="+1"><br>
                  </font><br>
                  <font face="Trebuchet MS" size="+1">
                    <meta charset="utf-8">
                  </font><font face="Trebuchet MS" size="+1"> </font></td>
                <td class="s4" width="300" height="120"><a
                    href="https://arxiv.org/abs/1908.10084"><font
                      face="Trebuchet MS" size="+1">Sentence-BERT:
                      Sentence Embeddings using Siamese-Networks</font></a><br>
                  <ul>
                    <li><a
href="https://towardsdatascience.com/advance-nlp-model-via-transferring-knowledge-from-cross-encoders-to-bi-encoders-3e0fc564f554"
                        moz-do-not-send="true"><font size="+1"><font
                            face="Trebuchet MS">Advance BERT model via
                            transferring from Cross-Encoders to
                            Bi-Encodes - Data Augmentation Method to
                            Improve SBERT Bi-Encoders for Pairwise
                            Sentence Scoring Tasks (semantic Sentence
                            Tasks)</font></font></a></li>
                    <li><font size="+1"><font face="Trebuchet MS"><a
href="https://towardsdatascience.com/a-complete-guide-to-transfer-learning-from-english-to-other-languages-using-sentence-embeddings-8c427f8804a9">A
                            Complete Guide to Transfer Learning From
                            English to Other Languages Using Sentence
                            Embeddings BERT Models</a><br>
                        </font></font></li>
                  </ul>
                  <font face="Trebuchet MS"></font></td>
                <td class="s4" width="380" height="120"><font
                    face="Trebuchet MS"><a
                      href="https://github.com/adsieg/text_similarity"><font
                        face="Trebuchet MS" size="+1">GitHub -
                        adsieg/text_similarity: Text Similarity</font></a>
                  </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="132"><font
                    face="Trebuchet MS" size="+1">6</font></td>
                <td class="s3" width="72" height="132"><font
                    face="Trebuchet MS" size="+1">4/6 &amp; 4/8</font><font
                    face="Trebuchet MS"><br>
                  </font></td>
                <td class="s4" width="390" height="132"><b><font
                      face="Trebuchet MS" size="+1">Sentence Embedding
                      with Transformers</font></b></td>
                <td class="s4" width="300" height="132"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><a
href="https://medium.com/dair-ai/making-monolingual-sentence-embeddings-multilingual-using-knowledge-distillation-59d8a7713672">Making








                        Monolingual Sentence Embeddings Multilingual
                        using Knowledge Distillation </a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/labse-language-agnostic-bert-sentence-embedding-by-google-ai-531f677d775f">LaBSE:Language-Agnostic








                        BERT Sentence Embeddings by Google AI</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/billion-scale-semantic-similarity-search-with-faiss-sbert-c845614962e2">Billion-scale








                        Semantic Similarity Search with FAISS+SBERT</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/how-to-build-a-semantic-search-engine-with-transformers-and-faiss-dcbea307a0e8">How








                        to Build Semantic Search with Transformers and
                        FAISS</a><br>
                    </font> </font></td>
                <td class="s4" width="380" height="132"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><a moz-do-not-send="true"
                        href="https://github.com/facebookresearch/faiss">Facebook





                        Faiss</a> : Library for efficient similarity
                      search and clustering of dense vectors.</font> </font></td>
              </tr>
              <tr>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1">7</font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"><font
                      face="Trebuchet MS" size="+1">4/13 &amp; 4/15</font>
                  </font> </td>
                <td valign="top" height="135"><b><font face="Trebuchet
                      MS" size="+1">Search with Transformers</font></b></td>
                <td valign="top" height="135">
                  <meta charset="utf-8">
                  <div data-pm-slice="1 1
[&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null},&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null},&quot;li&quot;,{&quot;style&quot;:null,&quot;checked&quot;:null,&quot;value&quot;:null,&quot;displayValue&quot;:2,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;listStyleType&quot;:null}]"
                    data-en-clipboard="true">
                    <ul>
                    </ul>
                    <font face="Trebuchet MS" size="+1"><a
                        moz-do-not-send="true"
href="https://rom1504.medium.com/semantic-search-with-embeddings-index-anything-8fb18556443c">Semantic

                        Search with Embeddings: index anythings</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/introducing-txtai-an-ai-powered-search-engine-built-on-transformers-37674be252ec">Introducing











                        txtai, an AI-Powered search engine on
                        Transformers&nbsp;</a></font>
                    <ul>
                    </ul>
                    <font face="Trebuchet MS" size="+1"><a
href="https://medium.com/analytics-vidhya/building-a-faster-and-accurate-search-engine-on-custom-dataset-with-transformers-d1277bedff3d">Building











                        a Faster and Accurate Search Engine on Custom
                        Dataset with Transformers</a><br>
                      <br>
                      <a moz-do-not-send="true"
href="https://towardsdatascience.com/deep-learning-for-semantic-text-matching-d4df6c2cf4c5#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6ImZkMjg1ZWQ0ZmViY2IxYWVhZmU3ODA0NjJiYzU2OWQyMzhjNTA2ZDkiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MTMxMzA5MjcsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwMzg3Mzk5MjE4Mzc3MTc1NDM1OCIsImVtYWlsIjoiaHNoaW40NEBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6Ikh5b3BpbCBTaGluIiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hLS9BT2gxNEdoaGhtbjEtQzBOd2x2cnYwWFZwNWNIRVVtUjhBMW9ZWU9rcWN1LUlnPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6Ikh5b3BpbCIsImZhbWlseV9uYW1lIjoiU2hpbiIsImlhdCI6MTYxMzEzMTIyNywiZXhwIjoxNjEzMTM0ODI3LCJqdGkiOiIyNTBhMTYzYmZiOTNiZjQ0ZDU0ZmFkZDM2ZjFlNTY1N2ZlNTAzMjU1In0.lCyGbHV8BoRGVjCWgyANTO08OsbN_JpLsp4rIOy6nL0nNwod4yhwJd4aBP8PqA7TbRA662bz0BsqdBu2DO0rbq9tJt7guW78eI_pK-Ndg5M20t2eqcG3UD-kBHB0J5gquugBAdwcw7lrZ6qPHIXX2HgQ45uWt83C0I1ejgRvMtOgekMDVLkocHmgeSRTf5G2_uSNaziJTkroeuxXUwWb5rPJ2ZnhqPg4QpGC3BdVz_mMkgikokqneCq_a5kSeWfQmB6mwe5tWtvoZ0c_2YoSM9UDp4U9pDffZzkUA8j9oOwR-PyJLdzpAtwT-5NsiNRTd3xa6glJeb2bMms60SoMTQ">Deep





                        Learning for Semantic Text Matching</a><br>
                    </font>
                    <ul>
                    </ul>
                  </div>
                </td>
                <td valign="top" height="135">
                  <ul>
                  </ul>
                  <font face="Trebuchet MS"><a
                      href="https://github.com/neuml/txtai"><font
                        size="+1">txtai</font></a></font>
                  <ul>
                  </ul>
                  <font face="Trebuchet MS" size="+1"><a
                      href="https://github.com/neuml/tldrstory">tldrstroy</a><br>
                  </font>
                  <ul>
                  </ul>
                </td>
              </tr>
              <tr>
                <td class="s2" height="135"><font face="Trebuchet MS"
                    size="+1">8</font></td>
                <td class="s3" height="135"><font face="Trebuchet MS"
                    size="+1">4/20 &amp; 4/22</font></td>
                <td class="s4" height="135"><b><font face="Trebuchet MS"
                      size="+1">Search with Transformers</font></b></td>
                <td class="s4" height="135"><font face="Trebuchet MS"
                    size="+1"><a
href="https://towardsdatascience.com/introducing-txtai-an-ai-powered-search-engine-built-on-transformers-37674be252ec">Introducing











                      txtai, an AI-Powered search engine on
                      Transformers&nbsp;</a></font>
                  <ul>
                  </ul>
                  <font face="Trebuchet MS" size="+1"><a
href="https://medium.com/analytics-vidhya/building-a-faster-and-accurate-search-engine-on-custom-dataset-with-transformers-d1277bedff3d">Building











                      a Faster and Accurate Search Engine on Custom
                      Dataset with Transformers</a><br>
                    <br>
                  </font><font face="Trebuchet MS" size="+1"><a
                      moz-do-not-send="true"
href="file:///Users/deeplearning/OneDrive/cl_course/NLPApplications/eyJhbGciOiJSUzI1NiIsImtpZCI6ImZkMjg1ZWQ0ZmViY2IxYWVhZmU3ODA0NjJiYzU2OWQyMzhjNTA2ZDkiLCJ0eXAiOiJKV1QifQ">Deep





                      Learning for Semantic Text Matching</a></font><br>
                  <ul>
                  </ul>
                  <font face="Trebuchet MS"> </font></td>
                <td class="s4" height="135"><font face="Trebuchet MS"><a
                      href="https://github.com/neuml/txtai"><font
                        size="+1">txtai</font></a></font><br>
                  <font face="Trebuchet MS" size="+1"><a
                      href="https://github.com/neuml/tldrstory">tldrstroy</a></font><br>
                  <font face="Trebuchet MS"> </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="150"><font
                    face="Trebuchet MS" size="+1">9</font><font
                    face="Trebuchet MS"><br>
                  </font></td>
                <td class="s3" width="72" height="150"><font
                    face="Trebuchet MS" size="+1">4/27 &amp; 4/29</font></td>
                <td class="s4" width="390" height="150"><b><font
                      face="Trebuchet MS" size="+1">Text Classification
                      /Generation with Transformers</font></b></td>
                <td class="s4" width="300" height="150"><a
href="https://towardsdatascience.com/siamese-and-dual-bert-for-multi-text-classification-c6552d435533"><font
                      face="Trebuchet MS" size="+1">Siamese and Dual
                      BERT for Multi Text Classification</font></a><br>
                  <br>
                  <a
href="(https://gmihaila.medium.com/gpt2-for-text-classification-using-hugging-face-transformers-574555451832"><font
                      size="+1"><font face="Trebuchet MS">GPT2 for Text
                        Classification using Huggingface Transformers</font></font></a><br>
                  <font face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"></font> </font></td>
                <td class="s4" width="380" height="150"><font
                    face="Trebuchet MS"><br>
                  </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="105"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><font size="+1">10</font> </font> </font>
                </td>
                <td class="s3" width="72" height="105"><font
                    face="Trebuchet MS" size="+1"><font size="+1">5/4
                      &amp; 5/6</font> </font></td>
                <td class="s4" width="390" height="105"><b><font
                      face="Trebuchet MS" size="+1">Text Classification
                      /Generation with Transformers</font></b></td>
                <td class="s4" width="300" height="105"><font
                    face="Trebuchet MS"><a
href="https://towardsdatascience.com/build-a-bidirectional-text-generator-with-xlnet-49d9d37b48a9"><font
                        face="Trebuchet MS" size="+1">Build a
                        Bidirectional Text Generation Using Pytorch</font></a><br>
                  </font><br>
                  <font face="Trebuchet MS"><a
href="https://medium.com/engineered-publicis-sapient/text-generation-in-any-language-with-gpt-2-e8fba8656167"><font
                        face="Trebuchet MS" size="+1">Text Generation in
                        Any Language with GPT-2&nbsp;</font></a> </font></td>
                <td class="s4" width="380" height="105"><font
                    face="Trebuchet MS"><br>
                  </font></td>
              </tr>
              <tr>
                <td valign="top" height="150"><font face="Trebuchet MS"
                    size="+1"><font face="Trebuchet MS" size="+1">11</font>
                  </font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"><font
                      face="Trebuchet MS" size="+1"><font size="+1">5/11
                        &amp; 5/13</font></font> </font> <font
                    face="Trebuchet MS" size="+1"><br>
                    <br>
                  </font></td>
                <td width="390" valign="top" height="150"><b><font
                      face="Trebuchet MS" size="+1">Summarization with
                      Transformers</font></b></td>
                <td width="300" valign="top" height="150"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><a
href="https://medium.com/practical-data-science-and-engineering/tldr-summarise-articles-and-content-with-nlp-a1a6e4e6316b">TLDR!!








                        Summarize Articles and Content With NLP </a><br>
                    </font><br>
                    <a
href="https://towardsdatascience.com/pegasus-google-state-of-the-art-abstractive-summarization-model-627b1bbbc5ce"><font
                        face="Trebuchet MS" size="+1">PEGASUS: </font><font
                        size="+1">Google's State of the Art Abstractive
                        Summarization Model</font></a><br>
                    <br>
                  </font><a
href="https://towardsdatascience.com/fine-tuning-a-t5-transformer-for-any-summarization-task-82334c64c81"><font
                      face="Trebuchet MS" size="+1">Fine Tuning a T5
                      Transformer for Any Summarization Task</font></a><br>
                  <font face="Trebuchet MS">
                    <meta charset="utf-8">
                  </font>
                  <div data-pm-slice="1 1
[&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null},&quot;ol&quot;,{&quot;style&quot;:null,&quot;start&quot;:null,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;lineHeight&quot;:null,&quot;listStyleType&quot;:null},&quot;li&quot;,{&quot;style&quot;:null,&quot;checked&quot;:null,&quot;value&quot;:null,&quot;displayValue&quot;:3,&quot;backgroundColor&quot;:null,&quot;color&quot;:null,&quot;listStyleType&quot;:null}]"
                    data-en-clipboard="true"><br>
                    <font face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/summarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944">Summarize








                        Reddit Comments using T5, BART, GPT-2, XLNet
                        Models</a><br>
                    </font><br>
                    <font face="Trebuchet MS" size="+1"><font
                        face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/discobert-a-bert-that-shortens-your-reading-time-be49d03e1ff">DiscoBERT:








                          A BERT that Shortens Your Reading Time</a><br>
                      </font></font></div>
                  <font face="Trebuchet MS"> </font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"><font
                      face="Trebuchet MS" size="+1"><a
                        href="https://arxiv.org/abs/1912.08777">PEGASUS:
                        Pre-training with Extracted Gap-sentences for
                        Abstractive Summarization </a>by Zhang et al.</font><br>
                    <br>
                  </font><font face="Trebuchet MS" size="+1"><a
                      href="https://www.aclweb.org/anthology/2020.acl-main.703/">BART:








                      Denoising Sequence-to-Sequence Pre-training for
                      Natural Language Generation, Translation, and
                      Comprehension </a>by Lewis et al.</font><br>
                  <font face="Trebuchet MS"><font face="Trebuchet MS"><span
                        style="color:rgb(36, 41, 46);"></span><span
                        style="color:rgb(36, 41, 46);"><br>
                      </span></font></font><font face="Trebuchet MS"
                    size="+1"><a
href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">Language








                      Models are Unsupervised Multitask Learners </a>by
                    Radford et al.</font><br>
                  <font face="Trebuchet MS"><font face="Trebuchet MS"><span
                        style="color:rgb(36, 41, 46);"></span></font><br>
                  </font><font face="Trebuchet MS"><a
                      href="https://www.aclweb.org/anthology/2020.acl-main.451.pdf"><font
                        face="Trebuchet MS" size="+1">Discourse-Aware
                        Neural Extractive Text Summarization&nbsp;&nbsp;</font></a>
                  </font></td>
              </tr>
              <tr>
                <td valign="top" height="150"><font face="Trebuchet MS"
                    size="+1">12</font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"
                    size="+1"><font size="+1"><font size="+1">5/18 &amp;
                        5/20</font></font></font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"
                    size="+1"><b>Multimodal Transformers</b><br>
                    <br>
                    <b>TAPAS</b><br>
                  </font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"><a
href="https://medium.com/georgian-impact-blog/how-to-incorporate-tabular-data-with-huggingface-transformers-b70ac45fcfb4"><font
                        face="Trebuchet MS" size="+1">Transformers with
                        Tabular Data: How to Incorporate Tabular Data
                        with Huggingface Transformers</font></a><br>
                    <br>
                    <font size="+1"><a
href="https://towardsdatascience.com/google-unveils-tapas-a-bert-based-neural-network-for-querying-tables-using-natural-language-b15e3e1c5543">Google








                        Unveils TAPAS, a BERT-based Neural Network for
                        Querying Tables Using Natural Language</a><br>
                      <br>
                      <a
href="https://medium.com/dataseries/google-tapas-is-a-bert-based-model-to-query-tabular-data-using-natural-language-2435a386b43f">Google








                        TAPAS is a BERT-based Model to Query Tabular
                        Data Using Neural Language</a><br>
                    </font> </font></td>
                <td valign="top" height="150"><font face="Trebuchet MS"><a
href="https://github.com/georgianpartners/Multimodal-Toolkit"><font
                        face="Trebuchet MS" size="+1">Multimodal
                        Transformers | Transformers with Tabular Data</font></a><br>
                    <br>
                    <br>
                  </font><font face="Trebuchet MS"><font face="Trebuchet
                      MS" size="+1"><a
                        href="https://www.aclweb.org/anthology/2020.acl-main.398.pdf">Weakly








                        Supervised Table Parsing via Pre-training</a> by
                      Herzig et al. </font><br>
                  </font><br>
                  <font face="Trebuchet MS"> </font></td>
              </tr>
              <tr>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1">13</font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1"><font size="+1">5/25 &amp; 5/27</font></font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1"><b>QA with Transformers</b><br>
                  </font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"><font
                      face="Trebuchet MS" size="+1"><a
href="https://towardsdatascience.com/bert-based-cross-lingual-question-answering-with-deeppavlov-704242c2ac6f">BERT-based








                        Cross-Lingual Question Answering with DeepPavlov</a><br>
                      <br>
                      <a
href="https://medium.com/swlh/how-to-finetune-mt5-to-create-a-question-generator-for-100-languages-4a3878e63118">How








                        to Finetune mT5 to Create a Question
                        Generator(for 100_Languages)</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/build-an-open-domain-question-answering-system-with-bert-in-3-lines-of-code-da0131bc516b">Build








                        an Open-Domain Question-Answering System With
                        BERT in 3 Lines of Code</a><br>
                      <br>
                      <a moz-do-not-send="true"
href="https://towardsdatascience.com/sentence2mcq-using-bert-word-sense-disambiguation-and-t5-transformer-e6bb5aaba29b">Sentence2MCQ






                        using BERT Word Sense Disambiguation and T5
                        Transformer</a><br>
                    </font> </font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"><a
                      href="https://github.com/deepset-ai/haystack"><font
                        face="Trebuchet MS" size="+1">Haystack: Neural
                        Question Answering at Scale</font></a> </font></td>
              </tr>
              <tr>
                <td class="s2" width="17" height="79"><font
                    face="Trebuchet MS" size="+1">14</font></td>
                <td class="s3" width="72" height="79"><font
                    face="Trebuchet MS" size="+1"> </font><font
                    face="Trebuchet MS" size="+1"><font size="+1">6/1
                      &amp; 6/3</font></font></td>
                <td class="s4" width="390" height="79"><b><font
                      face="Trebuchet MS" size="+1">Chatbot with
                      Transformers</font></b></td>
                <td class="s4" width="300" height="79"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><a
href="https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61">Chatbots








                        Were the Next Big Thing: What Happened? - The
                        Startup</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/chatbots-are-cool-a-framework-using-python-part-1-overview-7c69af7a7439">Chatbots








                        are Cool! A Framework Using Python</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/lets-build-an-intelligent-chatbot-7ea7f215ada6">Let's








                        Build an Intelligent Chatbot</a><br>
                      <br>
                      <a
href="https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30">Make








                        Your Own Rick Sanchez (bot) with Transformers
                        and DialoGPT Fine-Tuining<br>
                      </a><br>
                    </font><a
href="https://towardsdatascience.com/blender-bot-part-1-the-data-524beaedde65"><font
                        face="Trebuchet MS" size="+1">Blenderbot- Part
                        1: The Data</font></a><br>
                    <br>
                    <a
href="https://towardsdatascience.com/blender-bot-part-2-the-transformer-2e4d960b149f"><font
                        size="+1">Blenderbot - part 2: The Transformer</font></a><br>
                  </font></td>
                <td class="s4" width="380" height="79"><font
                    face="Trebuchet MS"><font face="Trebuchet MS"
                      size="+1"><a
                        href="https://arxiv.org/abs/2004.13637">Recipes
                        for Building an Open-domain Chatbot</a> by
                      Roller et al.</font> </font></td>
              </tr>
              <tr>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1">15</font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"
                    size="+1"><font size="+1">6/8 &amp; 6/10</font></font></td>
                <td valign="top" height="135"><b><font face="Trebuchet
                      MS" size="+1">Final Presentations</font></b></td>
                <td valign="top" height="135"><font face="Trebuchet MS"><br>
                  </font></td>
                <td valign="top" height="135"><font face="Trebuchet MS"><br>
                  </font></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
      <hr>
      <h2><font face="Trebuchet MS"><br>
        </font> </h2>
      <font face="Trebuchet MS"><br>
      </font> </div>
    <font face="Trebuchet MS"> </font>
  </body>
</html>
